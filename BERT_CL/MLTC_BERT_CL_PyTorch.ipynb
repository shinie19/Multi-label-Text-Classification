{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5HPJLrcczz3v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85c3812b-dbed-437f-b5a8-759fbac1977c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "21CfZBHF0Ij2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dca3fc01-6730-48d4-f56f-316cb5464b5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Mar 18 05:53:50 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   66C    P0    30W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "zGV1RVWi0KBf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import shutil\n",
        "import sys\n",
        "from sklearn.metrics import accuracy_score, classification_report"
      ],
      "metadata": {
        "id": "XzlqKdDd0NZ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = \"/content/drive/MyDrive/KLTN/Dataset/act/csv/train.csv\"\n",
        "test_path = \"/content/drive/MyDrive/KLTN/Dataset/act/csv/test.csv\""
      ],
      "metadata": {
        "id": "Ul90LxBE0RDT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv(train_path, delimiter=\"\\t\")\n",
        "test_df = pd.read_csv(test_path, delimiter=\"\\t\")"
      ],
      "metadata": {
        "id": "3vYlkqS00S1A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_list = train_df.columns[1:]\n",
        "label_list"
      ],
      "metadata": {
        "id": "kUodvaQq0UMF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42b272e1-b681-4367-f718-6fc0c2ba44c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Attraction-Inform', 'Attraction-NoOffer', 'Attraction-Recommend',\n",
              "       'Attraction-Request', 'Attraction-Select', 'Booking-Book',\n",
              "       'Booking-Inform', 'Booking-NoBook', 'Booking-Request',\n",
              "       'Hospital-Inform', 'Hospital-Request', 'Hotel-Inform', 'Hotel-NoOffer',\n",
              "       'Hotel-Recommend', 'Hotel-Request', 'Hotel-Select', 'Police-Inform',\n",
              "       'Police-Request', 'Restaurant-Inform', 'Restaurant-NoOffer',\n",
              "       'Restaurant-Recommend', 'Restaurant-Request', 'Restaurant-Select',\n",
              "       'Taxi-Inform', 'Taxi-Request', 'Train-Inform', 'Train-NoOffer',\n",
              "       'Train-OfferBook', 'Train-OfferBooked', 'Train-Request', 'Train-Select',\n",
              "       'general-bye', 'general-greet', 'general-reqmore', 'general-thank',\n",
              "       'general-welcome'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_labels(df):\n",
        "    labels = []\n",
        "    for i in range(len(df)):\n",
        "        row = []\n",
        "        for j in label_list:\n",
        "            if ((j in df.columns) and (df.iloc[i][j] == 1)):\n",
        "                row.append(1)\n",
        "            else:\n",
        "                row.append(0)\n",
        "        labels.append(row)\n",
        "    return labels\n",
        "\n",
        "Y_test = get_labels(test_df)"
      ],
      "metadata": {
        "id": "72nWUB9l0V3W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertModel"
      ],
      "metadata": {
        "id": "eezLyXjJ0Xet"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN = 256\n",
        "TRAIN_BATCH_SIZE = 32\n",
        "VALID_BATCH_SIZE = 32\n",
        "TEST_BATCH_SIZE = 32\n",
        "EPOCHS = 5\n",
        "LEARNING_RATE = 1e-05"
      ],
      "metadata": {
        "id": "uU-u_Ryr0Z3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, df, tokenizer, max_len, is_test_df):\n",
        "        self.df = df\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "        self.text = self.df['utterance']\n",
        "        if (is_test_df):\n",
        "            self.labels = get_labels(self.df)\n",
        "        else:\n",
        "            self.labels = self.df[label_list].values\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.text)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        text = str(self.text[index])\n",
        "        text = \" \".join(text.split())\n",
        "\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            None,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            return_token_type_ids=True,\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'input_ids': inputs['input_ids'].flatten(),\n",
        "            'attention_mask': inputs['attention_mask'].flatten(),\n",
        "            'token_type_ids': inputs[\"token_type_ids\"].flatten(),\n",
        "            'labels': torch.FloatTensor(self.labels[index])\n",
        "        }"
      ],
      "metadata": {
        "id": "1xVdFzEC0dA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BERTClassifier(nn.Module):\n",
        "    def __init__(self, num_labels):\n",
        "        super(BERTClassifier, self).__init__()\n",
        "        self.bert_model = BertModel.from_pretrained('bert-base-uncased', return_dict=True)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.fc = nn.Linear(self.bert_model.config.hidden_size, num_labels)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
        "        outputs = self.bert_model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
        "        pooled_output = outputs['pooler_output']\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.fc(pooled_output)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "7s84iRYI0e9F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def distance(tensor1, tensor2):\n",
        "    list1 = tensor1.tolist()\n",
        "    list2 = tensor2.tolist()\n",
        "\n",
        "    \"\"\"Distance between two vectors.\"\"\"\n",
        "    squares = [(p-q) ** 2 for p, q in zip(list1, list2)]\n",
        "    return sum(squares) ** .5"
      ],
      "metadata": {
        "id": "g7SSVYJk-BYX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def contrastive_loss(batch, logits, temperature):\n",
        "    contrastive_loss = 0\n",
        "    for i in range(len(batch['input_ids'])):\n",
        "        sum_labels = 0\n",
        "        sum_distances = 0\n",
        "        for k in range(len(batch['input_ids'])):\n",
        "            if (i != k):\n",
        "                sum_labels += torch.matmul(batch['labels'][i].t(), batch['labels'][k]).item()\n",
        "                sum_distances += math.exp((-1)*distance(logits[i], logits[k])/temperature)\n",
        "        for j in range(len(batch['input_ids'])):\n",
        "            if (i != j):\n",
        "                if (sum_labels == 0):\n",
        "                    sum_labels = 1e-06\n",
        "                contrastive_loss += (torch.matmul(batch['labels'][i].t(), batch['labels'][j]).item() / sum_labels) * math.log((math.exp((-1)*distance(logits[i], logits[j])/temperature)) / sum_distances)\n",
        "\n",
        "    return (-1)*contrastive_loss\n"
      ],
      "metadata": {
        "id": "j3-L9PfB7tsp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, training_loader, optimizer, criterion, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch in training_loader:\n",
        "        input_ids = batch['input_ids'].to(device, dtype = torch.long)\n",
        "        attention_mask = batch['attention_mask'].to(device, dtype = torch.long)\n",
        "        token_type_ids = batch['token_type_ids'].to(device, dtype = torch.long)\n",
        "        labels = batch['labels'].to(device, dtype = torch.float)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(input_ids, attention_mask, token_type_ids)\n",
        "        \n",
        "        loss = criterion(logits, labels)\n",
        "        # print('BCE Loss: ', loss)\n",
        "        # print('Contrastive Loss: ', contrastive_loss(batch, logits, 1))\n",
        "        loss += (0.01)*contrastive_loss(batch, logits, 10)\n",
        "        # print('Loss: ', loss)\n",
        "        # print(\"=======\")\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    return total_loss / len(training_loader)"
      ],
      "metadata": {
        "id": "43YIt6C_w6j6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate(model, validation_loader, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in validation_loader:\n",
        "            input_ids = batch['input_ids'].to(device, dtype = torch.long)\n",
        "            attention_mask = batch['attention_mask'].to(device, dtype = torch.long)\n",
        "            token_type_ids = batch['token_type_ids'].to(device, dtype = torch.long)\n",
        "            labels = batch['labels'].to(device, dtype = torch.float)\n",
        "\n",
        "            logits = model(input_ids, attention_mask, token_type_ids)\n",
        "            \n",
        "            loss = criterion(logits, labels)\n",
        "            loss += (0.01)*contrastive_loss(batch, logits, 10)\n",
        "\n",
        "            total_loss += loss.item()\n",
        "    return total_loss / len(validation_loader)"
      ],
      "metadata": {
        "id": "wsVHQd6cOewq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model, dataloader, device):\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            input_ids = batch['input_ids'].to(device, dtype = torch.long)\n",
        "            attention_mask = batch['attention_mask'].to(device, dtype = torch.long)\n",
        "            token_type_ids = batch['token_type_ids'].to(device, dtype = torch.long)\n",
        "\n",
        "            logits = model(input_ids, attention_mask, token_type_ids)\n",
        "\n",
        "            predictions.append(torch.sigmoid(logits).cpu().detach().numpy())\n",
        "    return np.concatenate(predictions)"
      ],
      "metadata": {
        "id": "JvBjMjF7Ogc8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_checkpoint(checkpoint_path, model, optimizer):\n",
        "    \"\"\"\n",
        "    checkpoint_path: path to save checkpoint\n",
        "    model: model that we want to load checkpoint parameters into       \n",
        "    optimizer: optimizer we defined in previous training\n",
        "    \"\"\"\n",
        "    # Load checkpoint\n",
        "    checkpoint = torch.load(checkpoint_path)\n",
        "    # Initialize state_dict from checkpoint to model\n",
        "    model.load_state_dict(checkpoint['state_dict'])\n",
        "    # Initialize optimizer from checkpoint to optimizer\n",
        "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "    # Initialize valid_loss_min from checkpoint to valid_loss_min\n",
        "    valid_loss_min = checkpoint['valid_loss_min']\n",
        "    # Return model, optimizer, epoch value, min validation loss \n",
        "    return model, optimizer, checkpoint['epoch'], valid_loss_min\n",
        "\n",
        "def save_checkpoint(state, is_best, checkpoint_path, best_model_path):\n",
        "    \"\"\"\n",
        "    state: checkpoint we want to save\n",
        "    is_best: is this the best checkpoint; min validation loss\n",
        "    checkpoint_path: path to save checkpoint\n",
        "    best_model_path: path to save best model\n",
        "    \"\"\"\n",
        "    f_path = checkpoint_path\n",
        "    # save checkpoint data to the path given, checkpoint_path\n",
        "    torch.save(state, f_path)\n",
        "    # if it is a best model, min validation loss\n",
        "    if is_best:\n",
        "        best_fpath = best_model_path\n",
        "        # copy that checkpoint file to best path given, best_model_path\n",
        "        shutil.copyfile(f_path, best_fpath)"
      ],
      "metadata": {
        "id": "TFzVvab8psT5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Main:**"
      ],
      "metadata": {
        "id": "rY_-VMc_OlJV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mubIiy26OiSm",
        "outputId": "373a8f46-7595-481d-8581-5c4cbccfc019"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize tokenizer and model\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BERTClassifier(len(label_list))\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "pximxMN0Oos8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize optimizer and loss function\n",
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)\n",
        "criterion = torch.nn.BCEWithLogitsLoss()"
      ],
      "metadata": {
        "id": "oDDNEg0WOp52"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "train_size = 0.8\n",
        "train_df2 = train_df.sample(frac=train_size, random_state=200)\n",
        "val_df = train_df.drop(train_df2.index).reset_index(drop=True)\n",
        "train_df=train_df2.reset_index(drop=True)\n",
        "\n",
        "train_dataset = CustomDataset(train_df, tokenizer, MAX_LEN, False)\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=TRAIN_BATCH_SIZE, shuffle=True, num_workers=0)\n",
        "\n",
        "valid_dataset = CustomDataset(val_df, tokenizer, MAX_LEN, False)\n",
        "valid_dataloader = torch.utils.data.DataLoader(valid_dataset, batch_size=VALID_BATCH_SIZE, shuffle=False, num_workers=0)\n",
        "\n",
        "test_dataset = CustomDataset(test_df, tokenizer, MAX_LEN, True)\n",
        "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=TEST_BATCH_SIZE, shuffle=False, num_workers=0)"
      ],
      "metadata": {
        "id": "Co8Nj0fCOr0s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and validate the model\n",
        "checkpoint_path = \"/content/drive/MyDrive/KLTN/Model/BERT_CL/curr_checkpoint\"\n",
        "best_model_path = \"/content/drive/MyDrive/KLTN/Model/BERT_CL/best_model.pt\"\n",
        "valid_loss_min = np.Inf\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    train_loss = train(model, train_dataloader, optimizer, criterion, device)\n",
        "    valid_loss = validate(model, valid_dataloader, criterion, device)\n",
        "    print(f'Epoch {epoch + 1}: train_loss = {train_loss:.4f}, valid_loss = {valid_loss:.4f}')\n",
        "\n",
        "    # Create checkpoint variable and add important data\n",
        "    checkpoint = {\n",
        "        'epoch': epoch + 2,\n",
        "        'valid_loss_min': valid_loss,\n",
        "        'state_dict': model.state_dict(),\n",
        "        'optimizer': optimizer.state_dict()\n",
        "    }\n",
        "\n",
        "    # Save checkpoint\n",
        "    save_checkpoint(checkpoint, False, checkpoint_path, best_model_path)\n",
        "\n",
        "    # Save the model if validation loss has decreased\n",
        "    if valid_loss <= valid_loss_min:\n",
        "      print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min, valid_loss))\n",
        "      # Save checkpoint as best model\n",
        "      save_checkpoint(checkpoint, True, checkpoint_path, best_model_path)\n",
        "      valid_loss_min = valid_loss"
      ],
      "metadata": {
        "id": "2rB0NHPZOwgO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8494999c-004a-469e-cd9b-2279cf84ea15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: train_loss = 0.9979, valid_loss = 0.9408\n",
            "Validation loss decreased (inf --> 0.940813).  Saving model ...\n",
            "Epoch 2: train_loss = 0.8553, valid_loss = 0.8951\n",
            "Validation loss decreased (0.940813 --> 0.895126).  Saving model ...\n",
            "Epoch 3: train_loss = 0.8181, valid_loss = 0.8742\n",
            "Validation loss decreased (0.895126 --> 0.874223).  Saving model ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load model and continue training:**"
      ],
      "metadata": {
        "id": "EHHvSmleRbql"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the model\n",
        "checkpoint_path = \"/content/drive/MyDrive/KLTN/Model/BERT_CL/best_model.pt\"\n",
        "\n",
        "model, optimizer, epoch, loss = load_checkpoint(checkpoint_path, model, optimizer)"
      ],
      "metadata": {
        "id": "IqkQxgNDRakc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(epoch)\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkyRgYgWSx7P",
        "outputId": "c6b44786-fb63-4204-caf2-f0d6ce2748c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n",
            "0.8742226623313528\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and validate the model\n",
        "checkpoint_path = \"/content/drive/MyDrive/KLTN/Model/BERT_CL/curr_checkpoint\"\n",
        "best_model_path = \"/content/drive/MyDrive/KLTN/Model/BERT_CL/best_model.pt\"\n",
        "valid_loss_min = loss\n",
        "\n",
        "for e in range(epoch, EPOCHS + 2):\n",
        "    train_loss = train(model, train_dataloader, optimizer, criterion, device)\n",
        "    valid_loss = validate(model, valid_dataloader, criterion, device)\n",
        "    print(f'Epoch {e}: train_loss = {train_loss:.4f}, valid_loss = {valid_loss:.4f}')\n",
        "\n",
        "    # Create checkpoint variable and add important data\n",
        "    checkpoint = {\n",
        "        'epoch': e + 1,\n",
        "        'valid_loss_min': valid_loss,\n",
        "        'state_dict': model.state_dict(),\n",
        "        'optimizer': optimizer.state_dict()\n",
        "    }\n",
        "\n",
        "    # Save checkpoint\n",
        "    save_checkpoint(checkpoint, False, checkpoint_path, best_model_path)\n",
        "\n",
        "    # Save the model if validation loss has decreased\n",
        "    if valid_loss <= valid_loss_min:\n",
        "      print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min, valid_loss))\n",
        "      # Save checkpoint as best model\n",
        "      save_checkpoint(checkpoint, True, checkpoint_path, best_model_path)\n",
        "      valid_loss_min = valid_loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DfFcsuNcR3Qz",
        "outputId": "f132e97f-8959-4b08-fafe-5e11ecb0f8b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4: train_loss = 0.7986, valid_loss = 0.8647\n",
            "Validation loss decreased (0.874223 --> 0.864679).  Saving model ...\n",
            "Epoch 5: train_loss = 0.7855, valid_loss = 0.8610\n",
            "Validation loss decreased (0.864679 --> 0.861017).  Saving model ...\n",
            "Epoch 6: train_loss = 0.7774, valid_loss = 0.8585\n",
            "Validation loss decreased (0.861017 --> 0.858514).  Saving model ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluation:**"
      ],
      "metadata": {
        "id": "vpXvK1W2RkKg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the model and evaluate\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "threshold = 0.5\n",
        "\n",
        "y_true = Y_test\n",
        "y_pred = predict(model, test_dataloader, device)\n",
        "\n",
        "for item in y_pred:\n",
        "    for j in range(len(y_pred[0])):\n",
        "        if (item[j] > threshold):\n",
        "            item[j] = 1\n",
        "        else:\n",
        "            item[j] = 0\n",
        "\n",
        "print(\"Test Accuracy : {}\".format(accuracy_score(y_true, y_pred)))\n",
        "print(\"\\nClassification Report : \")\n",
        "print(classification_report(y_true, y_pred, target_names=label_list))"
      ],
      "metadata": {
        "id": "_55JdETAOx76",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02f20181-b2d5-4c6a-e15d-4f1c4602c4ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy : 0.7777400976668475\n",
            "\n",
            "Classification Report : \n",
            "                      precision    recall  f1-score   support\n",
            "\n",
            "   Attraction-Inform       0.92      0.88      0.90      1522\n",
            "  Attraction-NoOffer       0.92      0.80      0.86        60\n",
            "Attraction-Recommend       0.71      0.66      0.69       148\n",
            "  Attraction-Request       0.81      0.69      0.74       676\n",
            "   Attraction-Select       0.64      0.53      0.58        55\n",
            "        Booking-Book       0.89      0.97      0.93       537\n",
            "      Booking-Inform       0.93      0.89      0.91       564\n",
            "      Booking-NoBook       0.98      0.95      0.97       131\n",
            "     Booking-Request       0.94      0.93      0.94       321\n",
            "     Hospital-Inform       0.00      0.00      0.00         0\n",
            "    Hospital-Request       0.00      0.00      0.00         0\n",
            "        Hotel-Inform       0.89      0.89      0.89      2156\n",
            "       Hotel-NoOffer       0.95      0.79      0.86        67\n",
            "     Hotel-Recommend       0.70      0.70      0.70       140\n",
            "       Hotel-Request       0.80      0.67      0.73       577\n",
            "        Hotel-Select       0.65      0.68      0.66        80\n",
            "       Police-Inform       0.60      1.00      0.75         3\n",
            "      Police-Request       0.00      0.00      0.00         0\n",
            "   Restaurant-Inform       0.88      0.90      0.89      2061\n",
            "  Restaurant-NoOffer       0.83      0.98      0.90       111\n",
            "Restaurant-Recommend       0.77      0.59      0.67       145\n",
            "  Restaurant-Request       0.77      0.66      0.71       583\n",
            "   Restaurant-Select       0.77      0.67      0.72        87\n",
            "         Taxi-Inform       0.95      0.91      0.93       604\n",
            "        Taxi-Request       0.85      0.75      0.80       236\n",
            "        Train-Inform       0.95      0.94      0.95      2401\n",
            "       Train-NoOffer       0.83      0.56      0.67         9\n",
            "     Train-OfferBook       0.93      0.86      0.89       380\n",
            "   Train-OfferBooked       0.96      0.79      0.87       297\n",
            "       Train-Request       0.91      0.90      0.90      1077\n",
            "        Train-Select       0.79      0.31      0.45        35\n",
            "         general-bye       0.89      0.97      0.93      1195\n",
            "       general-greet       0.67      0.02      0.03       240\n",
            "     general-reqmore       0.88      0.92      0.90      1439\n",
            "       general-thank       0.98      0.95      0.96       940\n",
            "     general-welcome       0.71      0.75      0.73       503\n",
            "\n",
            "           micro avg       0.89      0.86      0.88     19380\n",
            "           macro avg       0.77      0.71      0.72     19380\n",
            "        weighted avg       0.89      0.86      0.87     19380\n",
            "         samples avg       0.86      0.86      0.85     19380\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    }
  ]
}