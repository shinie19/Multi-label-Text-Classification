{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-xdAHLwSMMU",
        "outputId": "9cc3923b-e2e1-489f-edee-20d4e03301ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9jj9aEZSd6B",
        "outputId": "40427d1a-12db-461e-d4b4-ace438a1f071"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mon Mar  6 08:08:29 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   46C    P0    25W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QuC3zPPdSqLp"
      },
      "outputs": [],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uvcjoelpSs2F"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import shutil\n",
        "import sys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QdxNf193S621"
      },
      "outputs": [],
      "source": [
        "train_path = \"/content/drive/MyDrive/KLTN/Dataset/act/csv/train.csv\"\n",
        "test_path = \"/content/drive/MyDrive/KLTN/Dataset/act/csv/test.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UhVMqg0SS7jL"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv(train_path, delimiter=\"\\t\")\n",
        "test_df = pd.read_csv(test_path, delimiter=\"\\t\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 698
        },
        "id": "nR__hZpEULu5",
        "outputId": "74b842da-8ae9-42d2-9617-0c81c798d662"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-4bdc6a91-8f56-48af-a0b0-d7201adb6439\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>utterance</th>\n",
              "      <th>Attraction-Inform</th>\n",
              "      <th>Attraction-NoOffer</th>\n",
              "      <th>Attraction-Recommend</th>\n",
              "      <th>Attraction-Request</th>\n",
              "      <th>Attraction-Select</th>\n",
              "      <th>Booking-Book</th>\n",
              "      <th>Booking-Inform</th>\n",
              "      <th>Booking-NoBook</th>\n",
              "      <th>Booking-Request</th>\n",
              "      <th>...</th>\n",
              "      <th>Train-NoOffer</th>\n",
              "      <th>Train-OfferBook</th>\n",
              "      <th>Train-OfferBooked</th>\n",
              "      <th>Train-Request</th>\n",
              "      <th>Train-Select</th>\n",
              "      <th>general-bye</th>\n",
              "      <th>general-greet</th>\n",
              "      <th>general-reqmore</th>\n",
              "      <th>general-thank</th>\n",
              "      <th>general-welcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I'd really like to take my client out to a nic...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I show many restaurants that serve Indian food...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I am looking for an expensive indian restauran...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Might I recommend Saffron Brasserie? That is a...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Sure thing, please book for 6 people at 19:30 ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 37 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4bdc6a91-8f56-48af-a0b0-d7201adb6439')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4bdc6a91-8f56-48af-a0b0-d7201adb6439 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4bdc6a91-8f56-48af-a0b0-d7201adb6439');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                           utterance  Attraction-Inform  \\\n",
              "0  I'd really like to take my client out to a nic...                  0   \n",
              "1  I show many restaurants that serve Indian food...                  0   \n",
              "2  I am looking for an expensive indian restauran...                  0   \n",
              "3  Might I recommend Saffron Brasserie? That is a...                  0   \n",
              "4  Sure thing, please book for 6 people at 19:30 ...                  0   \n",
              "\n",
              "   Attraction-NoOffer  Attraction-Recommend  Attraction-Request  \\\n",
              "0                   0                     0                   0   \n",
              "1                   0                     0                   0   \n",
              "2                   0                     0                   0   \n",
              "3                   0                     0                   0   \n",
              "4                   0                     0                   0   \n",
              "\n",
              "   Attraction-Select  Booking-Book  Booking-Inform  Booking-NoBook  \\\n",
              "0                  0             0               0               0   \n",
              "1                  0             0               0               0   \n",
              "2                  0             0               0               0   \n",
              "3                  0             0               1               0   \n",
              "4                  0             0               0               0   \n",
              "\n",
              "   Booking-Request  ...  Train-NoOffer  Train-OfferBook  Train-OfferBooked  \\\n",
              "0                0  ...              0                0                  0   \n",
              "1                0  ...              0                0                  0   \n",
              "2                0  ...              0                0                  0   \n",
              "3                0  ...              0                0                  0   \n",
              "4                0  ...              0                0                  0   \n",
              "\n",
              "   Train-Request  Train-Select  general-bye  general-greet  general-reqmore  \\\n",
              "0              0             0            0              0                0   \n",
              "1              0             0            0              0                0   \n",
              "2              0             0            0              0                0   \n",
              "3              0             0            0              0                0   \n",
              "4              0             0            0              0                0   \n",
              "\n",
              "   general-thank  general-welcome  \n",
              "0              0                0  \n",
              "1              0                0  \n",
              "2              0                0  \n",
              "3              0                0  \n",
              "4              0                0  \n",
              "\n",
              "[5 rows x 37 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EckHanjgUgeQ",
        "outputId": "90f5d5e3-ad0d-46d0-f999-469371214e82"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['Attraction-Inform', 'Attraction-NoOffer', 'Attraction-Recommend',\n",
              "       'Attraction-Request', 'Attraction-Select', 'Booking-Book',\n",
              "       'Booking-Inform', 'Booking-NoBook', 'Booking-Request',\n",
              "       'Hospital-Inform', 'Hospital-Request', 'Hotel-Inform', 'Hotel-NoOffer',\n",
              "       'Hotel-Recommend', 'Hotel-Request', 'Hotel-Select', 'Police-Inform',\n",
              "       'Police-Request', 'Restaurant-Inform', 'Restaurant-NoOffer',\n",
              "       'Restaurant-Recommend', 'Restaurant-Request', 'Restaurant-Select',\n",
              "       'Taxi-Inform', 'Taxi-Request', 'Train-Inform', 'Train-NoOffer',\n",
              "       'Train-OfferBook', 'Train-OfferBooked', 'Train-Request', 'Train-Select',\n",
              "       'general-bye', 'general-greet', 'general-reqmore', 'general-thank',\n",
              "       'general-welcome'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "label_list = train_df.columns[1:]\n",
        "label_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QbYlfIQSndTJ"
      },
      "outputs": [],
      "source": [
        "def get_labels(df):\n",
        "    labels = []\n",
        "    for i in range(len(df)):\n",
        "        row = []\n",
        "        for j in label_list:\n",
        "            if ((j in df.columns) and (df.iloc[i][j] == 1)):\n",
        "                row.append(1)\n",
        "            else:\n",
        "                row.append(0)\n",
        "        labels.append(row)\n",
        "    return labels\n",
        "\n",
        "Y_test = get_labels(test_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_rskcPE9UtFW"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer, BertModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j1F3DcbbU6ip"
      },
      "outputs": [],
      "source": [
        "MAX_LEN = 256\n",
        "TRAIN_BATCH_SIZE = 32\n",
        "VALID_BATCH_SIZE = 32\n",
        "TEST_BATCH_SIZE = 32\n",
        "EPOCHS = 5\n",
        "LEARNING_RATE = 1e-05"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pvCaw98CVB9l"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, df, tokenizer, max_len, is_test_df):\n",
        "        self.df = df\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "        self.text = self.df['utterance']\n",
        "        if (is_test_df):\n",
        "            self.labels = get_labels(self.df)\n",
        "        else:\n",
        "            self.labels = self.df[label_list].values\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.text)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        text = str(self.text[index])\n",
        "        text = \" \".join(text.split())\n",
        "\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            None,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            return_token_type_ids=True,\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'input_ids': inputs['input_ids'].flatten(),\n",
        "            'attention_mask': inputs['attention_mask'].flatten(),\n",
        "            'token_type_ids': inputs[\"token_type_ids\"].flatten(),\n",
        "            'labels': torch.FloatTensor(self.labels[index])\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fPkBj8wUXOS7"
      },
      "outputs": [],
      "source": [
        "class BERTClassifier(nn.Module):\n",
        "    def __init__(self, num_labels):\n",
        "        super(BERTClassifier, self).__init__()\n",
        "        self.bert_model = BertModel.from_pretrained('bert-base-uncased', return_dict=True)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.fc = nn.Linear(self.bert_model.config.hidden_size, num_labels)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
        "        outputs = self.bert_model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
        "        pooled_output = outputs['pooler_output']\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.fc(pooled_output)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uks6BdSAYq-J"
      },
      "outputs": [],
      "source": [
        "def train(model, training_loader, optimizer, criterion, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch in training_loader:\n",
        "        input_ids = batch['input_ids'].to(device, dtype = torch.long)\n",
        "        attention_mask = batch['attention_mask'].to(device, dtype = torch.long)\n",
        "        token_type_ids = batch['token_type_ids'].to(device, dtype = torch.long)\n",
        "        labels = batch['labels'].to(device, dtype = torch.float)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(input_ids, attention_mask, token_type_ids)\n",
        "        loss = criterion(logits, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    return total_loss / len(training_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bmnItpDVauK_"
      },
      "outputs": [],
      "source": [
        "def validate(model, validation_loader, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in validation_loader:\n",
        "            input_ids = batch['input_ids'].to(device, dtype = torch.long)\n",
        "            attention_mask = batch['attention_mask'].to(device, dtype = torch.long)\n",
        "            token_type_ids = batch['token_type_ids'].to(device, dtype = torch.long)\n",
        "            labels = batch['labels'].to(device, dtype = torch.float)\n",
        "\n",
        "            logits = model(input_ids, attention_mask, token_type_ids)\n",
        "            \n",
        "            loss = criterion(logits, labels)\n",
        "            total_loss += loss.item()\n",
        "    return total_loss / len(validation_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hidMBSxVb_4s"
      },
      "outputs": [],
      "source": [
        "def predict(model, dataloader, device):\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            input_ids = batch['input_ids'].to(device, dtype = torch.long)\n",
        "            attention_mask = batch['attention_mask'].to(device, dtype = torch.long)\n",
        "            token_type_ids = batch['token_type_ids'].to(device, dtype = torch.long)\n",
        "\n",
        "            logits = model(input_ids, attention_mask, token_type_ids)\n",
        "\n",
        "            predictions.append(torch.sigmoid(logits).cpu().detach().numpy())\n",
        "    return np.concatenate(predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7497yTz3dKnD"
      },
      "source": [
        "**Main:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqFEGySZcyQY",
        "outputId": "87f2feae-71f7-4949-8872-b1be49436dc5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tz2vLlrCdP4w"
      },
      "outputs": [],
      "source": [
        "# Initialize tokenizer and model\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BERTClassifier(len(label_list))\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "foH0evq-di5m"
      },
      "outputs": [],
      "source": [
        "# Initialize optimizer and loss function\n",
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)\n",
        "criterion = torch.nn.BCEWithLogitsLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FfikxxIxd_Q9"
      },
      "outputs": [],
      "source": [
        "# Load data\n",
        "train_size = 0.8\n",
        "train_df2 = train_df.sample(frac=train_size, random_state=200)\n",
        "val_df = train_df.drop(train_df2.index).reset_index(drop=True)\n",
        "train_df=train_df2.reset_index(drop=True)\n",
        "\n",
        "train_dataset = CustomDataset(train_df, tokenizer, MAX_LEN, False)\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=TRAIN_BATCH_SIZE, shuffle=True, num_workers=0)\n",
        "\n",
        "valid_dataset = CustomDataset(val_df, tokenizer, MAX_LEN, False)\n",
        "valid_dataloader = torch.utils.data.DataLoader(valid_dataset, batch_size=VALID_BATCH_SIZE, shuffle=False, num_workers=0)\n",
        "\n",
        "test_dataset = CustomDataset(test_df, tokenizer, MAX_LEN, True)\n",
        "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=TEST_BATCH_SIZE, shuffle=False, num_workers=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "73pVuY1WiEZW"
      },
      "outputs": [],
      "source": [
        "def load_checkpoint(checkpoint_path, model, optimizer):\n",
        "    \"\"\"\n",
        "    checkpoint_path: path to save checkpoint\n",
        "    model: model that we want to load checkpoint parameters into       \n",
        "    optimizer: optimizer we defined in previous training\n",
        "    \"\"\"\n",
        "    # Load checkpoint\n",
        "    checkpoint = torch.load(checkpoint_path)\n",
        "    # Initialize state_dict from checkpoint to model\n",
        "    model.load_state_dict(checkpoint['state_dict'])\n",
        "    # Initialize optimizer from checkpoint to optimizer\n",
        "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "    # Initialize valid_loss_min from checkpoint to valid_loss_min\n",
        "    valid_loss_min = checkpoint['valid_loss_min']\n",
        "    # Return model, optimizer, epoch value, min validation loss \n",
        "    return model, optimizer, checkpoint['epoch'], valid_loss_min\n",
        "\n",
        "def save_checkpoint(state, is_best, checkpoint_path, best_model_path):\n",
        "    \"\"\"\n",
        "    state: checkpoint we want to save\n",
        "    is_best: is this the best checkpoint; min validation loss\n",
        "    checkpoint_path: path to save checkpoint\n",
        "    best_model_path: path to save best model\n",
        "    \"\"\"\n",
        "    f_path = checkpoint_path\n",
        "    # save checkpoint data to the path given, checkpoint_path\n",
        "    torch.save(state, f_path)\n",
        "    # if it is a best model, min validation loss\n",
        "    if is_best:\n",
        "        best_fpath = best_model_path\n",
        "        # copy that checkpoint file to best path given, best_model_path\n",
        "        shutil.copyfile(f_path, best_fpath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "doAc1f6Af8W0",
        "outputId": "5094fd2b-96f2-4926-e59d-1bdde386ed1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1: train_loss = 0.1121, valid_loss = 0.0492\n",
            "Validation loss decreased (inf --> 0.049183).  Saving model ...\n",
            "Epoch 2: train_loss = 0.0393, valid_loss = 0.0328\n",
            "Validation loss decreased (0.049183 --> 0.032809).  Saving model ...\n",
            "Epoch 3: train_loss = 0.0289, valid_loss = 0.0289\n",
            "Validation loss decreased (0.032809 --> 0.028887).  Saving model ...\n",
            "Epoch 4: train_loss = 0.0248, valid_loss = 0.0279\n",
            "Validation loss decreased (0.028887 --> 0.027902).  Saving model ...\n",
            "Epoch 5: train_loss = 0.0222, valid_loss = 0.0270\n",
            "Validation loss decreased (0.027902 --> 0.027026).  Saving model ...\n"
          ]
        }
      ],
      "source": [
        "# Train and validate the model\n",
        "checkpoint_path = \"/content/drive/MyDrive/KLTN/Model/BERT/curr_checkpoint\"\n",
        "best_model_path = \"/content/drive/MyDrive/KLTN/Model/BERT/best_model.pt\"\n",
        "valid_loss_min = np.Inf\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    train_loss = train(model, train_dataloader, optimizer, criterion, device)\n",
        "    valid_loss = validate(model, valid_dataloader, criterion, device)\n",
        "    print(f'Epoch {epoch + 1}: train_loss = {train_loss:.4f}, valid_loss = {valid_loss:.4f}')\n",
        "\n",
        "    # Create checkpoint variable and add important data\n",
        "    checkpoint = {\n",
        "        'epoch': epoch + 2,\n",
        "        'valid_loss_min': valid_loss,\n",
        "        'state_dict': model.state_dict(),\n",
        "        'optimizer': optimizer.state_dict()\n",
        "    }\n",
        "\n",
        "    # Save checkpoint\n",
        "    save_checkpoint(checkpoint, False, checkpoint_path, best_model_path)\n",
        "\n",
        "    # Save the model if validation loss has decreased\n",
        "    if valid_loss <= valid_loss_min:\n",
        "      print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min, valid_loss))\n",
        "      # Save checkpoint as best model\n",
        "      save_checkpoint(checkpoint, True, checkpoint_path, best_model_path)\n",
        "      valid_loss_min = valid_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TUSuX_2Nge21",
        "outputId": "e758f358-bc15-4dbe-bf0e-bf79b8551b2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy : 0.7755018990775909\n",
            "\n",
            "Classification Report : \n",
            "                      precision    recall  f1-score   support\n",
            "\n",
            "   Attraction-Inform       0.90      0.90      0.90      1522\n",
            "  Attraction-NoOffer       0.89      0.90      0.89        60\n",
            "Attraction-Recommend       0.74      0.62      0.67       148\n",
            "  Attraction-Request       0.87      0.62      0.73       676\n",
            "   Attraction-Select       0.67      0.53      0.59        55\n",
            "        Booking-Book       0.90      0.94      0.92       537\n",
            "      Booking-Inform       0.92      0.90      0.91       564\n",
            "      Booking-NoBook       0.98      0.93      0.95       131\n",
            "     Booking-Request       0.93      0.93      0.93       321\n",
            "     Hospital-Inform       0.00      0.00      0.00         0\n",
            "    Hospital-Request       0.00      0.00      0.00         0\n",
            "        Hotel-Inform       0.89      0.90      0.90      2156\n",
            "       Hotel-NoOffer       0.83      0.88      0.86        67\n",
            "     Hotel-Recommend       0.79      0.66      0.72       140\n",
            "       Hotel-Request       0.79      0.70      0.74       577\n",
            "        Hotel-Select       0.82      0.57      0.68        80\n",
            "       Police-Inform       0.60      1.00      0.75         3\n",
            "      Police-Request       0.00      0.00      0.00         0\n",
            "   Restaurant-Inform       0.92      0.87      0.89      2061\n",
            "  Restaurant-NoOffer       0.96      0.84      0.89       111\n",
            "Restaurant-Recommend       0.71      0.62      0.66       145\n",
            "  Restaurant-Request       0.77      0.67      0.71       583\n",
            "   Restaurant-Select       0.79      0.61      0.69        87\n",
            "         Taxi-Inform       0.96      0.90      0.93       604\n",
            "        Taxi-Request       0.85      0.75      0.79       236\n",
            "        Train-Inform       0.95      0.94      0.95      2401\n",
            "       Train-NoOffer       0.75      0.33      0.46         9\n",
            "     Train-OfferBook       0.91      0.87      0.89       380\n",
            "   Train-OfferBooked       0.93      0.81      0.87       297\n",
            "       Train-Request       0.91      0.88      0.90      1077\n",
            "        Train-Select       0.77      0.29      0.42        35\n",
            "         general-bye       0.91      0.96      0.93      1195\n",
            "       general-greet       0.71      0.02      0.04       240\n",
            "     general-reqmore       0.87      0.92      0.90      1439\n",
            "       general-thank       0.96      0.97      0.96       940\n",
            "     general-welcome       0.75      0.64      0.69       503\n",
            "\n",
            "           micro avg       0.90      0.86      0.88     19380\n",
            "           macro avg       0.78      0.69      0.71     19380\n",
            "        weighted avg       0.89      0.86      0.87     19380\n",
            "         samples avg       0.86      0.86      0.85     19380\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "# Test the model and evaluate\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "threshold = 0.5\n",
        "\n",
        "y_true = Y_test\n",
        "y_pred = predict(model, test_dataloader, device)\n",
        "\n",
        "for item in y_pred:\n",
        "    for j in range(len(y_pred[0])):\n",
        "        if (item[j] > threshold):\n",
        "            item[j] = 1\n",
        "        else:\n",
        "            item[j] = 0\n",
        "\n",
        "print(\"Test Accuracy : {}\".format(accuracy_score(y_true, y_pred)))\n",
        "print(\"\\nClassification Report : \")\n",
        "print(classification_report(y_true, y_pred, target_names=label_list))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
